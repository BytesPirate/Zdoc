---
title: "Extras 其他相关的知识"
description: "其他的 Nginx 内的知识"
---

::list{type="info"}
Nginx 内应该知道的知识
::

## Nginx 高性能并发模型 epoll 详解

在 epoll 模型之前，我们需要了解 IO 复用技术，同时 IO 复用技术具有多种实现方式，会分别介绍它们之前的不同以及区别。

接着，我们会介绍 IO 复用技术

### IO 复用技术

<img style="float:right" src="/img/devops/nginx/nginx-io.png"/>

IO 流请求操作系统内核，会分为串行处理和并行处理两个概念。

- 串行处理：简单来说，就是所有进程排好队，一个一个的来执行
- 并行处理：并行就是一起进行处理，同时并行与并发的概念是类似的，不同的是并发是逻辑上的同步运行，而并行是物理上的同步运行。

在串行处理的时候，后面所有的操作都需要等待，因此，出于现实情况的考虑，必须以并行处理的方式来完成整个 IO 流的请求，用来实现最大的并发和吞吐，这里就需要 IO 多路复用技术。

### IO 多路复用技术

IO 多路复用是指多个描述符的 I/O 操作都能在一个线程内并发交替地顺序完成，这里的复用是指复用同一个线程。

对于操作系统内核而言，多路复用其实是要完成操作系统的 IO 请求，对于 IO 文件的请求，当一个 IO 流要进行对应的文件处理的时候，要获取一组文件的描述符，当文件的描述符还没就绪的时候，它就一直在等待，直到描述符就绪，就马上上报一个系统的一个通知的机制，以此来告诉主应用程序它已经准备就绪了，你可以来进行操作了。这种方式就是 IO 多路复用系统。

### 技术实现

IO 多路复用技术的实现方式有 select、poll、epoll，它们都是 Linux 内核下的常见多路复用模型，接下来会根据时间发展顺序来逐步介绍各个模型。

## 模型介绍

### select 模型

<img style="float:right" src="/img/devops/nginx/select.png"/>

多路复用其实就是内核态对 IO 请求时，会主动地发送所需要处理的文件对象就绪时文件的就绪信息给应用端，应用端在 FD（File Description）没有就绪之前都是 block，也就是阻塞对应的 Socket 请求，也会维护一个 FD 的列表。

当内核态发送可用的信息，FD 就绪之后，应用端采用 select 这种模型，就会一直在遍历所维护的 FD 文件描述符的列表，以等到唤醒对应的线程完成对应的数据拷贝。select 模型能够监视文件描述符的数量存在最大限制，且在整个过程中，select 模型采用的是线性遍历的模式，这种模式效率低下。

### epoll 模型

epoll 模型优化和完善了 select 模型的缺点，每当 FD 就绪，采用系统的回调函数直接将 FD 放入，效率高，无监视文件描述符的数量限制，而 epoll 的原理也不难理解。

试着设想这样的一个场景：有100万用户同时与一个进程保持着TCP连接，而每一时刻只有几十个或几百个TCP连接是活跃的（接收到TCP包），也就是说，在每一时刻，进程只需要处理这100万个连接中的一小部分连接。那么，如何才能高效地处理这种场景呢？进程是否在每次询问操作系统收集有事件发生的TCP连接时，把这100万个连接告诉操作系统，然后由操作系统找出其中有事件发生的几百个连接呢？实际上，在Linux内核2.4版本之前，select或poll事件驱动模型就是这样处理的。

这里有个非常明显的问题，即在某一时刻，进程收集有事件的连接时，其实这100万连接中的大部分是没有事件发生的。因此，如果每次收集事件时，都把这100万连接的套接字传给操作系统（这首先就是用户态内存到内核态内存的大量复制），而由操作系统内核寻找这些连接上有没有未处理的事件，将会是巨大的资源浪费，然而select和poll就是这样做的，因此它们最多只能处理几千个并发连接。

而epoll就厉害了，它会在Linux内核中申请一个简易的文件系统，把原先的一个select或poll调用分成了3个部分：

1. 调用epoll_create创建一个epoll对象（在epoll文件系统中给这个句柄分配资源，一棵红黑树和一个准备就绪list链表）。

2. 调用epoll_ctl向epoll对象中添加这100万个连接的套接字。就是把socket放到红黑树上，给内核中断处理程序注册一个回调函数，然后告诉内核如果这个句柄的中断到了，就把这个socket放到准备就绪list链表里。

3. 调用epoll_wait收集发生事件的TCP连接。到准备就绪list链表中处理socket，并把数据返回给用户。

这样，只需要在进程启动的时候建立1个epoll对象，并在需要的时候向它添加或删除连接即可。因此在实际收集事件时，epoll_wait的效率会非常高，因为调用epoll_wait时并没有向它传递这100万个连接，内核也不需要去遍历所有的连接，只需要到就绪list链表中去处理socket就行了。